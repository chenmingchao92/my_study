# 并发



- 可见性：一个线程对共享变量的修改，另一个线程能够理科看到
- 当两个线程并行执行加法（比如循环10000000)的时候，他的值会更加接近于10000000 ，而不是20000000。（个人理解，因为线程有交替运行的时候，就是一个线程运行，而另一个线程没有运行，此时只有一个线程运行的时候，就会让数值单独增加一会，然后另一个线程起来，读取这个值到缓存（应该是每一段时间，cpu缓存中的数值就会刷新到内存中），两个线程在一起跑，他们都只读自己cpu缓存中的数值，而不读内存中的，此时就导致 要加的数据以期增加。因此 他的结果接近1000000 而不是20000000. 其实也就是下边的cpu时间片的机制
- **至于什么时候把数据从缓存写到内存，没有固定的时间**
- cpu时间片：一个线程执行一段时间，就交给另一个线程在执行一段时间。每一段时间就是一个cpu时间片
- 我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性。
- 

count+1  需要的CPU指令数：

1. 把变量从内存加载到CPU的寄存器
2. 在寄存器中进行+1操作
3. 将结果写入内存/缓存

因为上述原因的存在，当cpu进行切换的时候，就很容易产生bug

![image-20210131135431911](../picture/image-20210131135431911.png)

- 有序性：编译器调整代码执行的先后循序：例如对于new指令来说：

  1. 分配一块内存地址
  2. 在内存地址上初始化对象
  3. 将此内存地址赋值给指向这个对象的指针

  然后编译器优化成了：

  1. 分配一块内存地址
  2. 将此内存地址赋值给指向这个对象的指针
  3. 在内存地址上初始化对象

于是这就出了问题。（对于双重检查的单例来说）此时如果a线程再执行完b步骤之后，就把权限给了c。此时c拿到的就是一个没有初始化的变量，一用就出问题了。

![image-20210131135943265](../picture/image-20210131135943265.png)

除了编译器有序性优化外：CPU和解释器在运行期也会做一部分优化，所以很多时候都是看不到的，也很难重现

**因此很多的并发问题都是：原子性，可见性，有序性所引发的，他们是并发bug之源，要想写好多线程一定要打破这三个条件，我们要解决的就是这三个问题**

**在采用一项技术的同时，一定要清楚它带来的问题是什么，以及如何规避。**



为什么要使用volatile：	https://www.cnblogs.com/huiAlex/p/9037020.html

有如下代码：

```java
public class RunThread extends Thread{
    private boolean isRunning = true;
    public boolean isRunning(){
        return isRunning;
    }

    public void setRunning(boolean isRunning){
        this.isRunning = isRunning;
    }

    @Override
    public void run() {
        System.out.println("进入run...");
        while(isRunning==true){}
        System.out.println("线程停止了");
    }
}



import java.util.concurrent.TimeUnit;

public class Run {
    public static void main(String[] args){
        try{
            RunThread thread = new RunThread();
            thread.start();
            TimeUnit.MILLISECONDS.sleep(1000);
            thread.setRunning(false);
            System.out.println("赋值为false");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

执行结果：

我们创建了一个RunThread对象，并启动了该线程。当 isRunning == True时，将一直进行while循环。可以看到，我们启动了线程之后就调用setRunning方法将isRunning设为false。

按道理来说，当isRunning的状态为false时，就会退出while循环，输出“赋值为false”。然后run方法执行结束，线程执行完毕，整个程序运行结束。

但通过执行结果发现，线程进入了while死循环，线程从未终止。

![img](https://images2018.cnblogs.com/blog/956352/201805/956352-20180515085213675-1818293627.png)

这是由于在启动RunThread.java线程时，变量 private boolean isRunning = True 存在于公共堆栈和线程的私有堆栈中。JVM以server模式运行时，为了提高运行效率，线程一直从私有堆栈中读取isRunning的值为True。而thread.setRunning(false)执行后，是把公共堆栈中的isRunning改为false。所以即便将isRunning改为false，程序依然进入了while死循环。

 

解决办法：

使用volatile关键字，把 private boolean isRunning = True 改为 volatile private boolean isRunning = True ，再次运行：

![img](https://images2018.cnblogs.com/blog/956352/201805/956352-20180515085315379-297924505.png)

**volatile的作用是：强制线程从公共堆栈中取变量的值，而非从线程的私有堆栈中取值**

**![img](https://images2018.cnblogs.com/blog/956352/201805/956352-20180515092443220-1521333090.png)![img](https://images2018.cnblogs.com/blog/956352/201805/956352-20180515092607188-384526766.png)**



关于为甚如果同时有两个线程 分别执行 100000此 i++操作 中 i如果被标注为 volatile的时候，计算出来的值可能要会小于100000的原因：并不是线程二没有触发MESI，而是因为自增操作本身并不具备原子性，比如i++,分开来就是读取i的值到工作内存，计算i+1这个值（可以将这个值理解为temp，这个值可能保存在工作内存中某个地方，这不重要），将这个值赋值给i，假设线程2触发了MESI，线程1重新读取i，这里不会重新计算i+1（temp）这个步骤，而是将之前计算的i+1（temp）赋值给i，然后将i写回主存，这也是为什么说volatile只能保证可见性不能保证原子性，**其实是这个中间变量temp捣的鬼**

如果 上述的i没有被volatile操作，那他的值会比100000多一点的原因是，有一个线程先启动，然后他会将计算的一部分值刷新到主内存中，然后第二个线程启动的时候，从主内存中获取到值，其实这里也会发生比100000少的可能性，比如99910等值，我个人猜测也是因为临时变量的原因，和上述一样

为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为：

CPU 增加了缓存，以均衡与内存的速度差异；

操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；

编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。->指令优化只是编译器优化能力的一种。 指令一般都是由两部分组成：操作码和操作地址。 在计算机大量的指令当中有着“二·八”定则，指的是有着20%的指令在80%的时间里重复使用着，而80%的指令只有20%的时间在使用着。 那么为了提高计算机的工作效率，在指令的调用上，要想办法把那20%的指令尽可能的放在近的地方，而那剩下的指令可以放在稍微远一些的地方，例如： 比如第1行：a=8
第1000行：a=a*2;

这个时候，把他们放到一起执行，是不是就能更好的利用缓存了（这要求中间的几百行，没有对a使用）？

操作系统允许每个进程（其实就是线程，因为调度的单位就是线程）运行一段时间，就切换其他线程（任务切换），例如是50ms，50ms后，操作系统就会切换其他的线程，这个50ms就是时间片，**所以我们的线程并不是一直运行的，他是会隔一段时间才运行一段时间。**  。任务切换的时机大多数是在时间片结束的时候

![image-20210217225406136](D:\my_study\my_study\picture\image-20210217225406136.png)

没开啥东西，线程就这么多，他切换的能不厉害么。。。 所以i++这种要三条CPU指令的语法，容易出问题就不奇怪了。

spring 默认创建的是单例，多线程共享这个单例，自然就存在并发问题了

## java内存模型

java内存模型：解决**可见性**和**有序性**导致的问题

掌握java内存模型，有助于解决 可见性和有序性引发的问题。

- 导致可见性的 原因是缓存，导致有序性的问题是编译优化。解决这两个最直接的方式：**全部禁用缓存和编译优化**，但这明显不合理
- 所以我们要按需禁用缓存和编译优化->因为何时禁用只有程序员知道，所以**按需就是按照程序员的要求禁用**。
- 为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。
- 站在程序员的角度：java内存模型可以理解为：**java内存模型规范了jvm如何提供按需禁用缓存和编译优化的方法**
- 这些方法包括：volatile，synchronized，final 三个关键字，以及六项Happend-Before原则。

### volatile

> 告诉编译器：不能使用cpu缓存，必须从内存中读取或写入,并强制其他缓存中的数据失效

- Happen-Before：**前面的一个操作的结果对后续操作是可见的**
- Happen-Before：为程序员提供了按需禁用缓存和编译优化的行为
- 比较正式的说法是：Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 Happens-Before 规则。

#### 1.程序的循序执行

> 在一个**线程**中，按照程序顺序，前面的操作Happen-Before于后续的任意操作，一个线程内保证语意的串行性（即如果b依赖于a  那么 a一定先与b 执行，但是 如果 a和b没有依赖关系，则不一定）
> 在一个线程内，按照控制流顺序，书写在前面的操作先行 发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循 环等结构。
>
> 个人理解：就是对于单一线程，程序的运行结果，要符合程序程序员书写的逻辑，就是你编译器无论怎么优化，、程序的执行看起来，要和没有优化的时候样子一样。

因此 对于一些没有前后依赖关系的代码，就可以进行指令重排序了

```java

// 以下代码来源于【参考1】
class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }
  public void reader() {
    if (v == true) {
      // 这里x会是多少呢？
    }
  }
}
```

上述代码中 在同一个线程里 x =42 就要先用v=true执行，

### 2：volatile变量规则

> 对一个volatile的写操作，Happen-Before于对这个变量的读操作

对一个 volatile 变量的写操作相对于后续对这个 volatile 变量的读操作可见，这怎么看都是禁用缓存的意思

### 3.传递性

> 如果 A Happen-Before B  B Happen-Before C  那么 A  Happen-Before C

如下图所示，传递性的效果

![image-20210131153433499](../picture/image-20210131153433499.png)

“x=42” Happens-Before 写变量 “v=true” ，这是规则 1 的内容；

写变量“v=true” Happens-Before 读变量 “v=true”，这是规则 2 的内容 。

再根据这个传递性规则，我们得到结果：“x=42” Happens-Before 读变量“v=true”。这意味着什么呢？如果线程 B 读到了“v=true”，那么线程 A 设置的“x=42”对线程 B 是可见的。也就是说，线程 B 能看到 “x == 42” ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的，这个在后面的内容中会详细介绍。

个人理解：假设只有一个线程运行，那么     x = 42;v = true; 没有语义的先后循序 ，因此可以进行指令重排序

当有两个线程的时候，同时 v 被标注为 volatile 的时候，就给v以及在v之前进行的赋值操作，强制加了一个语义循序（依赖于 happen-before 第三条），因此 才能肯定读到v=42

指令重排序：在cpu执行指令的过程中，对于同一个线程中没有`数据依赖`的指令可以重新排序优化，有数据依赖的指令按照顺序串行执行，来保证单线程程序运行的正确性，同时也提升了CPU的执行效率，合理的利用了CPU等待时间，

我理解 volatile 就是在cpu指令级别上，加了一个写锁，在对volatile对象进行写入的时候，加上了写锁，所有读都必须等待其写完之后，才能读取



### 4：管程中锁的规则

> 对一个锁的解锁Happens-Before于后续对这个锁的加锁 ->这条一般也要配合 3.传递性一起使用 

管程：管程是一种通用的同步原语，在Java中指的就是synchronized，synchronized就是java对管程的实现

这也就是先进入管程中的程序对管程中数据的操作，对于后续进入管程的程序来说，完全可见

锁操作是具备happens-before关系的，解锁操作happens-before之后对同一把锁的加锁操作。 实际上，在解锁的时候，JVM需要强制刷新缓存，使得当前线程所修改的内存对其他线程可见。

一个线程对一个锁临界区执行完解锁后，变量的值对于另外线程后续对这个临界区做加锁操作时是可见的

### 5：线程start()规则

这是关于线程启动的，它是指主线程A启动子线程B后，子线程B能看到主线程A在启动B之前的操作  ->这条一般也要配合 3.传递性一起使用。

### 6：线程join()规则

这条是关于线程等待的，它是指主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现）当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程中的操作，即对“**共享变量**的操作”  -> 这条 一般也要配合3.传递性一起使用

换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。具体可参考下面示例代码。

volatile：禁用缓存和编译优化

final可以安全发布对象

“逸出”有点抽象，我们还是举个例子吧，在下面例子中，在构造函数里面将 this 赋值给了全局变量 global.obj，这就是“逸出”，线程通过 global.obj 读取 x 是有可能读到 0 的。因此我们一定要避免“逸出”。

```java
// 以下代码来源于【参考1】
final int x;
// 错误的构造函数
public FinalFieldExample() { 
  x = 3;
  y = 4;
  // 此处就是讲this逸出，
  global.obj = this;
}
```

Happens-Before 的语义是一种因果关系。在现实世界里，如果 A 事件是导致 B 事件的起因，那么 A 事件一定是先于（Happens-Before）B 事件发生的，这个就是 Happens-Before 语义的现实理解

在java语言里，Happen-Before的语义本质上是一种可见性，A Happens-Before B 意味着 A 事件对 B 事件来说是可见的，无论 A 事件和 B 事件是否发生在同一个线程里。例如 A 事件发生在线程 1 上，B 事件发生在线程 2 上，Happens-Before 规则保证线程 2 上也能看到 A 事件的发生。

### 7:线程中断规则：

> 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。

，volatile字段可以看成是一种不保证原子性的同步但保证可见性的特性，其性能往往是优于锁操作的。但是，频繁地访问 volatile字段也会出现因为不断地强制刷新缓存而影响程序的性能的问题

final修饰符，final修饰的实例字段则是涉及到新建对象的发布问题。当一个对象包含final修饰的实例字段时，其他线程能够看到已经初始化的final实例字段，这是安全的

所谓顺序，指的是你可以用顺序的方式推演程序的执行，但是程序的执行不一定是完全顺序的。编译器保证***结果***一定 == 顺序方式推演的结果 ->所以才造成了指令重排序

**这几条规则，都是告诉你，可以按照这个规则推演程序的执行。但是编译怎么优化，那就百花齐放了。**

volatile强制所修饰的变量及它前边	的变量刷新至内存，并且volatile禁止了指令的重排序。

volatile的一种解释：https://blog.csdn.net/weixin_30342639/article/details/91356608

## 互斥锁：解决原子性问题

一个或多个操作，在cpu执行过程中不被中断的特性，称为“原子性”

**原子性问题的源头：线程切换**

- 同一时刻只有一个线程执行，这个条件非常总要，我们称之为 **互斥**，如果我们能够保证对共享变量的修改时互斥的，那么无论是单核还是多核cpu，都能保证数据的正确性
- 需要互斥执行的代码称为 **临界区**

锁模型如下：

![image-20210202211030705](D:\my_study\my_study\picture\image-20210202211030705.png)

首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。很多并发 Bug 的出现都是因为把它忽略了，然后就出现了类似锁自家门来保护他家资产的事情，这样的 Bug 非常不好诊断，因为潜意识里我们认为已经正确加锁了。

- synchronized可以修饰静态方法，非静态发方法，代码块
- 对应synchronized来说：当修饰静态方法的时候，锁定的是当前类的Class对象，当修饰的是非静态方法的时候，锁定的是当前实例对象this
  - 受保护的资源和锁之间的关系：**一个合理的关系是：受保护的资源和锁之间是多对一的关系**，就是可以用一把锁保护多个资源

**加锁本质就是在锁对象的对象头中写入当前线程id**

sync锁的对象monitor指针指向一个ObjectMonitor对象，所有线程加入他的entrylist里面，去cas抢锁，更改state加1拿锁，执行完代码，释放锁state减1，和aqs机制差不多，只是所有线程不阻塞，cas抢锁，没有队列，属于非公平锁

当线程释放一个锁时会强制性的将工作内存中之前所有的写操作都刷新到主内存中去，而获取一个锁则会强制性的加载可访问到的值到线程工作内存中来。虽然锁操作只对同步方法和同步代码块这一块起到作用，但是影响的却是线程执行操作所使用的所有字段。

volatile告诉编译器：对这个变量的读写，不能使用cpu缓存，必须从内存中都读取或写入

- 用不同的锁对受保护的资源进行精细化管理，能够提升性能，这种锁叫细粒度锁：例如 存款 取款 可以用同一把锁，查看密码，修改密码，也可以用同一把锁，着就是细粒度锁。当然我们也可以存款，取款，查密码，改密码全用一把锁，着就是粗粒度锁。

如何保护多个资源已经很有心得了，关键是要分析多个资源之间的关系。如果资源之间没有关系，很好处理，每个资源一把锁就可以了。如果资源之间有关联关系，就要选择一个粒度更大的锁（例如Xxx.class)，这个锁应该能够覆盖所有相关的资源。除此之外，还要梳理出有哪些访问路径，所有的访问路径都要设置合适的锁

- 关联关系（比如转账：A转给B100）如果用更具体更专业的语言描述的话，其实是一种“原子性”特征，我们提到的原子性，主要是面向 CPU 指令的，转账操作的原子性则是属于是面向高级语言的，不过它们本质上是一样的

  - 原子性的本质是什么：其实不是不可分割，不可分割只是外在的表现，其本质是多个资源之间有一致性的要求， **操作的中间状态对外不可见** 。例如，在 32 位的机器上写 long 型变量有中间状态（只写了 64 位中的 32 位），在银行转账的操作中也有中间状态（账户 A 减少了 100，账户 B 还没来得及发生变化），i++中也有中间状态

  **不可用可变对象做锁！！** 如果一个对象里边的某个字段发生了值的变化，是没有问题的，但是如果是引用变了，那就凉凉了，所以我们做锁的对象，最好用final标识符进行修饰。

死锁的一个比较专业的定义是：一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。

### 如何预防死锁：

预防死锁：只需要破坏如下四个条件中的一个即可。

- **互斥：共享的资源x和y只能被一个线程占用**->*这条是不能被破坏的，因为我们多线程就是要互斥的访问共享资源*
- 占有且等待：线程T1已经占有x资源，在他等待y资源的同时，不释放x资源
- 不可抢占：其他资源不能强行抢占线程T1占有的资源
- 循环等待：线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源就是循环等待

只要破坏上述的一条就能破坏死锁

### 破坏占有且等待

要破坏这个条件，可以一次性申请所有的资源：已转账操作为例

​	![image-20210208215904811](D:\my_study\my_study\picture\image-20210208215904811.png)

“同时申请”这个操作也是一个临界区，我们也需要一个角色，来管理这个临界区，我们就把这个角色定义为Allocator，他又两个重要的功能，分别是同时申请资源apply()和同时释放资源free()，账户类Account中持有ALlocator的一个单例（必须是单例，只能由一个人来分配），当账户Account再执行转账操作的时候，首先像Allocator同时申请转入账户和转出账户这两个资源，成功后在锁定这两个资源，当转账操作执行完，释放锁后，我们需要通知Allocator同时释放转出账户和转入账户这两个资源

```java

class Allocator {
  private List<Object> als =
    new ArrayList<>();
  // 一次性申请所有资源
  synchronized boolean apply(
    Object from, Object to){
    if(als.contains(from) ||
         als.contains(to)){
      return false;  
    } else {
      als.add(from);
      als.add(to);  
    }
    return true;
  }
  // 归还资源
  synchronized void free(
    Object from, Object to){
    als.remove(from);
    als.remove(to);
  }
}

class Account {
  // actr应该为单例
  private Allocator actr;
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    // 一次性申请转出账户和转入账户，直到成功
    while(!actr.apply(this, target))  //此处其实应该有个timeout
      ；
    try{
      // 锁定转出账户
      synchronized(this){              
        // 锁定转入账户
        synchronized(target){           
          if (this.balance > amt){
            this.balance -= amt;
            target.balance += amt;
          }
        }
      }
    } finally {
      actr.free(this, target)
    }
  } 
}
```

### 破坏不可抢占条件

用java.util.concurrent这个包下提供的Lock是可以轻松加解决的

### 破坏循环等待条件

破坏这个条件，需要对资源进行排序，然后按顺序申请资源，例如对于账号id来说，每个账号都有id，我们就可以利用这个顺序来做文章，申请资源的时候，我们就可以按照id从小到大的顺序来申请

如下代码所示①到⑥是我们要执行的转账逻辑

```java

class Account {
  private int id;
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    Account left = this        ①
    Account right = target;    ②
    if (this.id > target.id) { ③
      left = target;           ④
      right = this;            ⑤
    }                          ⑥
    // 锁定序号小的账户
    synchronized(left){
      // 锁定序号大的账户
      synchronized(right){ 
        if (this.balance > amt){
          this.balance -= amt;
          target.balance += amt;
        }
      }
    }
  } 
}
```

这里肯定不会发生死锁的，比如 有三个账号1,2,3  1和2相互转账，2和3相互转账，如果T1拿到了id1的锁，此时切换线程，T2拿到了线程2的锁，此时在切换线程到T1，T1获取不到id2的锁没错，但是等到T2的时候T2可以获取到id3的锁，此时他可以正常转账，等他这里操作完了，就能进行id1和id2之间的转账了

人能智能的交流，但是两个线程之间是没有这个能力的。因此很多人理所当然的事情，在线程上就发生了死锁了。

用细粒度锁来锁定多个资源的时候，要注意死锁的问题，并把它生成为一个思维定式，一遇到这种场景，就要想到死锁的可能性。不同的破坏死锁条件的方式，花费的成本也不同，例如上述的破坏不可抢占条件的，就成本很高，但是，破坏循环等待的，就成本很低。

循环等待，一定是A->B->C->...->N->A形成环状。
如果按顺序申请，是不允许N->A出现的，只能N->P。没有环状，也就不会死锁了

## 等待-通知 优化循环等待

我们上边的避免死锁的一个方式是 破坏“占有且等待”的这个条件，当时我们用的是：

```java

// 一次性申请转出账户和转入账户，直到成功
while(!actr.apply(this, target))
  ；
```

这种死循环的方式，如果并发量小，他还可以，如果并发量大，需要循环上万次才能拿到锁，那就操蛋了。

这种情况下最好的方式是：如果条件不满足（转入转出的账本没有同时可用），线程就进行 **等待** 状态，当条件满足以后，**通知**等待的线程重新执行。**其中线程等待的方式，就能避免循环等待消耗CPU的问题**

- 线程进入等待状态，要释放持有的互斥锁
- 当处于等待状态的线程条件满足了，还需要去重新去获取互斥锁

**一个完整的等待-通知机制：线程首先获取互斥锁，当线程要求的条件不满足的时候，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁**

### 用synchronized实现等待通知

synchronized配合 wait() notify() notifyAll() 就能轻松实现。

对于synchronized保护的临界区，同一时刻，只有一个线程可以进入，其他的线程就要在该互斥锁的等待队列上进行等待。**互斥锁和等待队列是一对一的关系，每个互斥锁都有自己的等待队列**

当线程进入synchronized保护的临界区后，由于需要的条件不满足，可以调用 java的wait()方法进入等待状态，**进入等待状态的线程就会释放互斥锁，并进入该互斥锁的另一个等待队列中**，因为临界区中的线程释放了锁，所以其他线程就有机会获取到这个锁

![image-20210211103623478](D:\my_study\my_study\picture\image-20210211103623478.png)

当线程条件满足后：就可以调用 notify()方法 **通过调用wait()方法进入等待队列的线程**（上图右侧的队列）**条件曾经满足过**，因为notify只能保证，**他通知的那个时刻，条件是满足的**，被通知线程的执行时间，和通知的时间点一般都不会一致，所以当被通知的线程执行的时候，条件可能就不满足了（其他线程插队）。

而且被通知的线程，想要再一次进入临界区，任然需要重新获取锁，因为他之前的锁在调用wait()函数的时候已经被释放掉了

![image-20210211112810845](D:\my_study\my_study\picture\image-20210211112810845.png)

我们要注意的是：wait(),notify(),notifyAll()方法操作的等待队列是某个互斥锁的等待队列，因此，如果我们的互斥锁是this，那么对应的就是this.wait,this.notify,this.notifyAll()  同理 如果我们锁的是 target对象，那么就是target.wait(),target.notify,target.notifyA(), this.wait()是不能为 target.notify()唤醒的，因为他们不是一个互斥锁的队列。

而且我们调用这三个方法的条件之一就是：**线程已经获取了锁** 因为我们会发现，他们都是在synchronized {} 临界区内获取到的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。

notify会唤醒队列最前边的哪一个线程

因为等待-通知 有条件曾经满足过的问题，所以我们在让线程等待的时候，最好用如下的方式,这是一种范式，意思就是这是一种经典做法

```java
while(条件不满足) {
    wait();
  }	
```

例如我们可以吧之前破坏“占有且等待”的代码改成如下：

```java
class Allocator {
    private List<Object> als;
    synchronized void apply(Object from,Object to) {
        while(als.contains(from)||als.contains(to)) {
            wait();
        }
        als.add(from);
        als.add(to);
    }
    synchronized void release(Object from ,Object to) {
        als.remove(from);
        als.remove(to);
        notifyAll();
    }
}
```

### 尽量使用notifyAll()

***notify()会随机的通知等待队列中的一个线程*，而notifyAll()会通知等待队列中的所有线程**，如果我们使用notify()，造成的问题就是 **某些线程可能永远都不会被通知到**，如下例子，解释了如果使用notify 可能会发生的问题

*假设我们有资源 A、B、C、D，线程 1 申请到了 AB，线程 2 申请到了 CD，此时线程 3 申请 AB，会进入等待队列（AB 分配给线程 1，线程 3 要求的条件不满足），线程 4 申请 CD 也会进入等待队列。我们再假设之后线程 1 归还了资源 AB，如果使用 notify() 来通知等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。* 	

所以除非经过深思熟虑，否则尽量使用 notifyAll()；

所以当我们使用循环来等待某个状态的话，就可以改成用等待-通知的方式（线程协作的方式）

wait与sleep区别在于：
1. wait()方法与sleep()方法的不同之处在于，wait()方法会释放对象的“锁标志”。当调用某一对象的wait()方法后，会使当前线程暂停执行，并将当前线程放入对象等待池中，直到调用了notify()方法后，将从对象等待池中移出任意一个线程并放入锁标志等待池中，只有锁标志等待池中的线程可以获取锁标志，它们随时准备争夺锁的拥有权。当调用了某个对象的notifyAll()方法，会将对象等待池中的所有线程都移动到该对象的锁标志等待池。
   sleep()方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。
2. sleep是Thread的方法，wait()是Object的方法。

notify 只会唤醒，因为调用wait()方法而陷入等待的队列，而不会唤醒，从一开始就没有获取到锁的队列

## 安全性，活跃性和性能问题

### 安全性问题：

> 安全性的含义就是：程序按照我们期望的执行，不会发生意外情况

理论上，避免了原子性，可见性，有序性问题的程序就是线程安全的。

- **只有同时存在共享数据且该数据会发生变化，两个条件共存**，通俗的将就是多个线程会同时读写同一数据的时候，才会发生安全性问题。	
- 如果数据不共享或者共享数据不发生变化，就能解决这个问题了，例如ThreadLocal类就是让线程不共享，不变模式就是让共享数据不可变。

### 安全性问题的主要两个方面：

1. 数据竞争：当多个线程同时访问一个数据，并且至少有一个线程执行写入操作，如果我们不采取措施，就会导致bug。如下代码如果两个线程同时执行，就会发生数据竞争

   ```java
   public class Test {
     private long count = 0;
     void add10K() {
       int idx = 0;
       while(idx++ < 10000) {
         count += 1;
       }
     }
   }
   ```

2. 竞态条件：线程的执行结果依赖线程执行的顺序或者说是程序执行依赖于某个状态变量，如下代码所示就是一种竞态条件：

   ```java
   public class Test {
     private long count = 0;
     synchronized long get(){
       return count；
     }
     synchronized void set(long v){
       count = v;
     } 
     void add10K() {
       int idx = 0;
       while(idx++ < 10000) {
         set(get()+1)      
       }
     }
   }
   ```

   上述代码中 虽然我们给 get()和set()加锁了，但 add10k()中  set(get()+1) 这段并不是一个原子操作，可能两个线程先后调用get()  此时两个线程得到的值都是0，此时 他们就是依据获取到的这个值进行set() 结果就是错误的：**这就是竞态条件中的，程序的执行结果依赖于程序执行的顺序**

   对于另一种，**程序的执行依赖于某个状态变量** 的示例代码如下：

   ```java
   class Account {
     private int balance;
     // 转账
     void transfer(
         Account target, int amt){
       if (this.balance > amt) {
         this.balance -= amt;
         target.balance += amt;
       }
     } 
   }
   ```

   这是转账操作，要求账户余额必须>0  如果balance只有300  ，如果线程T1执行if后，发现满足要求，此时T2抢到了CPU 也执行了if，发现同样满足要求，然后T1和T2同时执行 this.balance -= amt;这条语句，就会导致balance，这就是 **程序的执行依赖于某个状态变量** 也就是如下语句：

   ```
   if (状态变量 满足 执行条件) {
     执行操作
   }
   ```

   当某个线程发现状态满足后，开始执行操作，可是当这个线程执行操作的时候，有其他的线程也执行同样的操作，导致状态变量变的不在满足执行条件了。**很多场景下，这个条件是不显示的，例如前面的add10K()方法中，set(get()+1)的操作，就隐式依赖get()的结果**

3. 解决上述的 **数据竞争** 和 **竞态条件** 的方式就是用 **互斥** 也就是 **锁** 的技术来解决

4. 数据竞争会引发竞态条件的问题。

### 活跃性问题

> 当程序无法执行下去的时候，就发生了活跃性问题，**死锁** 就是一种常见的活跃性问题，除此之外还有 **活锁 和饥饿**

- 发生死锁后，线程会相互等待，并且会一直等待下去，在技术上表现为：线程永久的阻塞了。

活锁：线程没有发生阻塞，但是仍然存在执行不下去的情况，这就是所谓的活锁（活锁没有堵塞，顾名思义，一直在运行，但是没有执行有效代码）：

- 例如两个人相向而行，都想给对方让路，一个往左一个往右，然后发现不行，又同时一个往右一个往左，如此反复，就是活锁。

- 又比如：活锁典型的例子实在一些重试机制中，比如以太网络上，两个基站尝试使用相同的载波发送数据包，包会发生冲突。发生冲突后，稍后都会重发。如果这时他们都是在 **1s 后（时间固定  ）**重发，那么他们又会再次发生冲突，一直循环下去，导致数据包永远不能发送。如下是一个活锁的代码：

  ```java
  /************************
   * 活锁例子
   * 创建一个勺子类，有且只有一个。
   * 丈夫和妻子用餐时，需要使用勺子，这时只能有一人持有，也就是说同一时刻只有一个人能够进餐。
   * 但是丈夫和妻子互相谦让，都想让对方先吃，所以勺子一直传递来传递去，谁都没法用餐。
   * */
  public class LiveLockTest {
  
      //定义一个勺子，ower 表示这个勺子的拥有者
      static class Spoon {
          Diner owner;//勺子的拥有者
  
          //获取拥有者
          public String getOwnerName() {
              return owner.getName();
          }
          //设置拥有者
          public void setOwner(Diner diner) {
              this.owner = diner;
          }
  
          public Spoon(Diner diner) {
              this.owner = diner;
          }
          //表示正在用餐
          public void use() {
              System.out.println(owner.getName() + " use this spoon and finish eat.");
          }
      }
  
      //定义一个晚餐类
      static class Diner {
          public Diner(boolean isHungry, String name) {
              this.isHungry = isHungry;
              this.name = name;
          }
          private boolean isHungry;//是否饿了
          private String name;//定义当前用餐者的名字
  
          public String getName() {//获取当前用餐者
              return name;
          }
          //可以理解为和某人吃饭
          public void eatWith(Diner spouse, Spoon sharedSpoon) {
              try {
                  synchronized (sharedSpoon) {
                      while (isHungry) {
                          //当前用餐者和勺子拥有者不是同一个人，则进行等待
                          while (!sharedSpoon.getOwnerName().equals(name)) {
                              sharedSpoon.wait();
                              //System.out.println("sharedSpoon belongs to" + sharedSpoon.getOwnerName())
                          }
                          //spouse此时是饿了，把勺子分给他，并通知他可以用餐
                          if (spouse.isHungry) {
                              System.out.println("I am " + name + ", and my " + spouse.getName() + " is hungry, I should give it to him(her).\n");
                              sharedSpoon.setOwner(spouse);
                              sharedSpoon.notifyAll();
                          } else {
                              //用餐
                              sharedSpoon.use();
                              sharedSpoon.setOwner(spouse);
                              isHungry = false;
                          }
                          Thread.sleep(500);
                      }
                  }
              } catch (InterruptedException e) {
                  System.out.println(name + " is interrupted.");
              }
          }
      }
  
      public static void main(String[] args) {
          final Diner husband = new Diner(true, "husband");//创建一个丈夫用餐类
          final Diner wife = new Diner(true, "wife");//创建一个妻子用餐类
          final Spoon sharedSpoon = new Spoon(wife);//创建一个勺子，初始状态并由妻子持有
  
          //创建一个 线程，由丈夫进行用餐
          Thread h = new Thread() {
              @Override
              public void run() {
                  //表示和妻子用餐，这个过程判断妻子是否饿了，如果是，则会把勺子分给妻子，并通知她
                  husband.eatWith(wife, sharedSpoon);
              }
          };
          h.start();
  
          //创建一个 线程，由妻子进行用餐
          Thread w = new Thread() {
              @Override
              public void run() {
                  //表示和妻子用餐，这个过程判断丈夫是否饿了，如果是，则会把勺子分给丈夫，并通知他
                  wife.eatWith(husband, sharedSpoon);
              }
          };
          w.start();
  
          try {
              Thread.sleep(10000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
          h.interrupt();
          w.interrupt();
  
          try {
              h.join();//join()方法阻塞调用此方法的线程(calling thread)，直到线程t完成，此线程再继续；通常用于在main()主线程内，等待其它线程完成再结束main()主线程。
              w.join();
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
      }
  }
  
  ```

  解决活锁的一个一般性的办法就是，尝试等待一个随机的时间就可以了（但是显然上述的我们妻子丈夫用餐的方式，不能这么解决），例如上述中，让路的例子和发信号的例子都可以通过等待一个随机时间解决

### 饥饿问题

> 饥饿：线程因无法访问所需资源而无法执行下去的情况

如果线程优先级不同，在cpu繁忙的情况下，优先级低的线程就很难被执行到，也就发生了线程的“饥饿”。或者持有锁的线程执行时间过长，也会导致饥饿。

解决饥饿有如下三种方式：

1. 保证资源充足
2. 公平的分配资源
3. 避免持有锁的线程执行时间过长

1和3适应的场景比较有限，因为在很多场景下，资源稀缺是无法避免的，同时线程持有锁的执行时间也很难缩短。

在并发编程中，主要是使用公平锁来保证公平的分配资源，公平锁：是一种先来后得到的方案，线程等待是有顺序的，排在队列前面的线程会优先获取资源。

### 性能问题

当锁的粒度过大，就会造成过大范围的串行化，这也就违背了我们是用并发的初衷->用并发挺高程序的执行性能。

阿姆达尔定律：处理器并行运算后，效率提升能提升多少：
$$
S=1/((1−p)+n/p)
$$
n： cpu的核数，p：并行百分比，  1-p 就是串行百分比，例如串行百分比为 5% n为无穷大，那么加速比S最大就20，也就是如果我们有5%的串行代码，那么我们无论采用什么技术，最高也就提高20倍速度。

所以使用锁的时候，一定要注意锁对性能的影响，**JDK并发包中之所以有这么多东西，有很大一部分原因就是要提高在某个特定领域的性能。**

使用无锁的算法和数据结构可以讲解决上述性能的问题：例如线程本地存储（Thread Local Storage TLS），写时复制，乐观锁等，已经jdk包的原子类

减少锁的持有时间（减少串行化的时间）增加并行化的时间：例如使用细粒度锁，concurrentHashMap中的分段锁，以及读写锁->读的时候无锁，写的时候才会加锁

性能方面的指标主要有以下三种：

1. 吞吐量：单位时间内程序能处理的请求数量，吞吐量越多，说明性能越好。
2. 延迟：从发出请求到收到响应的时间，延迟越短，说明性能越好
3. 并发量：指同一时间能处理的请求的数量，一般来说随着并发量的增加，延迟也会增加，所以延迟这个指标：一般会是基于并发量这个指标来说的，例如并发量是1000的时候，延迟是50ms

## 管程：并发编程的万能钥匙

管程的英  文名：Monitor

操作系统的课程告诉我们：用信号量能解决所有并发编程中遇到的问题

java采用的就是管程技术：synchronized关键字和 wait() notify() notifyAll() 三个方法都是管程的组成部分，

管程和信号量是等价的。即用管程能实现信号量，用信号量也能实现管程

**管程 **：**管理共享变量以及对共享变量的操作过程**，翻译成java领域语言：管理类的成员变量和成员方法，让这个类是线程安全的。

java管程的实现参考的 MESA模型

并发编程领域，有两大核心问题：

1. 互斥：同一时刻只能有一个线程访问资源。
2. 同步：程之间如何协作和通信

同步一般建立在互斥的基础上，只有资源具有排他性才需要同步来解决并发过程中对资源的协作问题。

管程解决互斥的方式：将共享变量和共享变量的操作封装起来，例如：实现一个线程安全的阻塞队列，可见将线程不安全的队列封装起来，对外提供线程安全的操作方法，例如出队和入队操作。

利用管程，可以快速实现这个直观的想法。在下图中，管程 X 将共享变量 queue 这个线程不安全的队列和相关的操作入队操作 enq()、出队操作 deq() 都**封装**起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。

![image-20210213124018405](D:\my_study\my_study\picture\image-20210213124018405.png)

管程模型和面向对象高度契合的。估计这也是 Java 选择管程的原因吧

管程解决线程同步的方式：

MESA的管程模型图如下所示：

![image-20210213142253752](D:\my_study\my_study\picture\image-20210213142253752.png)

在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在**入口等待队列**中等待。

管程里还引入了条件变量的概念，而且**每个条件变量都对应有一个等待队列**，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。

那条件变量和条件变量等待队列的作用是什么呢？其实就是解决线程同步问题。你可以结合上面提到的阻塞队列的例子加深一下理解（阻塞队列的例子，是用管程来实现线程安全的阻塞队列，这个阻塞队列和管程内部的等待队列没有关系，本文中一定要注意**阻塞队列和等待队列是不同的**）

例如：

假设有个线程 T1 执行阻塞队列的出队操作，执行出队操作，需要注意有个前提条件，就是**阻塞队列不能是空**的（空队列只能出 Null 值，是不允许的），阻塞队列不空这个前提条件对应的就是管程里的条件变量。 如果线程 T1 进入管程后恰好发现阻塞队列是空的，那怎么办呢？等待啊，去哪里等呢？就去**条件变量对应的等待队列里面等。**此时线程 T1 就去“队列不空”这个条件变量的等待队列中等待

再假设之后另外一个线程 T2 执行阻塞队列的入队操作，入队操作执行成功之后，**“阻塞队列不空”这个条件对于线程 T1 来说已经满足了，此时线程 T2 要通知 T1，告诉它需要的条件已经满足了**。**当线程 T1 得到通知后，会从等待队列**里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面

如下代码所示：

```java

public class BlockedQueue<T>{
  final Lock lock =
    new ReentrantLock();
  // 条件变量：队列不满  此处就对应着一个等待队列
  final Condition notFull =
    lock.newCondition();
  // 条件变量：队列不空  此处同样对应着一个等待队列
  final Condition notEmpty =
    lock.newCondition();

  // 入队
  void enq(T x) {
    lock.lock();
    try {
      while (队列已满){
        // 等待队列不满 
        notFull.await();
      }  
      // 省略入队操作...
      //入队后,通知可出队
      notEmpty.signal();
    }finally {
      lock.unlock();
    }
  }
  // 出队
  void deq(){
    lock.lock();
    try {
      while (队列已空){
        // 等待队列不空
        notEmpty.await();
      }
      // 省略出队操作...
      //出队后，通知可入队
      notFull.signal();
    }finally {
      lock.unlock();
    }  
  }
}
```

**在MESA模型中有一个编程范式：就是需要在一个while循环里调用wait()**.这是MESA管程模型特有的

```java
while(条件不满足) {
  wait();
}
```

hasen，Hoare，MESA三种管程模型的一个核心的区别是：

1. hasen模型中，要求notify() 放到最后，这样T2通知T1之后，就执行完了，T1再继续执行，这样能保证同一时刻只有一个线程执行
2. hoare模型中，没有要求notify()放到最后，但是在T2通知T1后，T2会陷入阻塞状态，T1马上执行，等T1执行完，在唤醒T2，它也能保证同一时刻只有一个线程再执行，但是相比于hasen，他多了一次阻塞唤醒操作
3. MESA模型：不要求notify()放到最后，并且T2通知T1以后，T2继续执行，T1从条件等待的队列转移到了入口等待队列中等待执行，这样做的好处是notify不用放到最后，也不需要阻塞T2，但是坏处是当T2执行完了之后，之前满足的条件可能不满足了，所以才需要进行while的循环wait()判断

除非满足以下三个条件，否则尽量使用notifyAll()方法

1. 所有等待线程拥有相同的等待条件
2. 所有等待线程被唤醒后，执行相同的操作
3. 只需要唤醒一个线程。

1.管程是一种概念，任何语言都可以通用。
2.在java中，每个加锁的对象都绑定着一个管程（监视器）
3.线程访问加锁对象，就是去拥有一个监视器的过程。如一个病人去门诊室看医生，医生是共享资源，门锁锁定医生，病人去看医生，就是访问医生这个共享资源，门诊室其实是监视器（管程）。
4.所有线程访问共享资源，都需要先拥有监视器。就像所有病人看病都需要先拥有进入门诊室的资格。
5.监视器至少有两个等待队列。一个是进入监视器的等待队列一个是条件变量对应的等待队列。后者可以有多个。就像一个病人进入门诊室诊断后，需要去验血，那么它需要去抽血室排队等待。另外一个病人心脏不舒服，需要去拍胸片，去拍摄室等待。
6.监视器要求的条件满足后，位于条件变量下等待的线程需要重新在门诊室门外排队，等待进入监视器。就像抽血的那位，抽完后，拿到了化验单，然后，重新回到门诊室等待，然后进入看病，然后退出，医生通知下一位进入。

当线程被唤醒后，是从wait命令后开始执行的(不是从头开始执行该方法，这点上老师的示意图容易让人产生歧义)，而执行时间点往往跟唤醒时间点不一致，所以条件变量此时不一定满足了，所以通过while循环可以再验证，而if条件却做不到，它只能从wait命令后开始执行，所以要用while

wait(time) 当等待了time这么长时间后，发现依然没人唤醒他，就会自动醒来，自己在试试 但是依然会在while这个循环圈里

java用两种方式实现了管程①synchronized+wait、notify、notifyAll②lock+内部的condition，第一种只支持一个条件变量，即wait，调用wait时会将其加到等待队列中，被notify时，会随机通知一个线程加到获取锁的等待队列中，第二种相对第一种condition支持中断和增加了时间的等待，lock需要自己进行加锁解锁，更加灵活，两个都是可重入锁，但是lock支持公平和非公平锁，synchronized支持非公平锁

管程是一种并发编程的模型，java中重量级锁的加锁解锁，都是借助管程Monitor，Monitior底层是用c++实现的，直接和系统内核交户，线程的切换，加锁解锁，都需借助操作系统才能完成，开销很大，所以java在并发包中，也提供了并发包，其实就是解决重量级锁线程阻塞带来的开销问题，并发包中的AQS 就是管程的翻版，只不过把线程的阻塞，换成了自旋，这样避免了线程阻塞的开销，同时在并发包中也提供了公平和非公平锁的接口**，java 原生的管程模型，进行加锁解锁，是非公平的，会导致饥饿问题**。

synchronized 解决互斥问题， wait()、notify()、notifyall()解决同步问题。

在synchronized实现的管程中，**调用wait方法的句柄就是条件变量**

## java线程的生命周期

java语言里的线程本质上就是操作系统的线程，他们是一一对应的

java线程生命周期要点->**要搞懂生命周期中各个节点的状态转换机制**

### 通用的线程声明周期

其他语言的线程的声明周期基本上也来自于此

通用的生命周期一共有五种状态，他们分别是：**初始状态，可运行状态，运行状态，休眠状态和终止状态**，如下图所示：

![image-20210213175419619](D:\my_study\my_study\picture\image-20210213175419619.png)

五种状态的详细情况如下：

1. **初始状态**：指线程已经被创建，但是还不允许分配cpu执行，这个状态属于编程语言特有的，不过这里所谓的被创建仅仅是编程语言层面的被创建，而在操作系统层面，真正的线程还没有被创建
2. **可运行状态**：指的线程可以被分配CPU，在这种状态下，真正的操作系统线程已经被创建出来了，所以可以分配CPU执行了。
3. **运行状态**：当有空闲的cpu时，操作系统会将其分配给一个处于可运行状态的线程，被分配到CPU的线程的状态就转换成了运行状态。
4. **休眠状态**：运行时状态的线程如果调用了一个阻塞的API(例如以阻塞的方式读文件)或者等待某个事件（例如条件变量），那么线程的状态就会转变成休眠状态，同时释放cpu的使用权，休眠状态的线程有永远没有机会获取CPU使用权
5. **终止状态**：线程执行完或者出现异常就会进入终止状态，终止状态的线程，不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了。

**jvm把可运行状态和运行状态合并了，因为jvm不关心这两个状态，因为jvm吧线程的调度交给了操作系统**

jvm细化了休眠状态。

### java中线程的声明周期

java线程共有六种状态

1. NEW（初始化状态）
2. RUNNABLE(可运行/运行状态)
3. BLOCKED（阻塞状态）
4. WAITING(无时限等待状态)
5. TIMED_WAITING(有时限等待)
6. TERMINATED（终止状态）

在操作系统层面 BLOCKED WAITING TIME_WAITING 是一种状态->休眠状态，**只要Java县城处于这三种状态之一，那么这个线程就永远没有CPU的使用权**

![image-20210213183814112](D:\my_study\my_study\picture\image-20210213183814112.png)

BLOCKED WAITING TIME_WAITING是线程进入休眠状态的三种原因。

### RUNNABLE和BLOCKED状态的转换

只有一种场景会触发这种转换->线程等待synchronized的隐式锁，单线程获取到synchronized的隐式锁的时候，就能从BLOCKED切换到RUNNABLE状态

线程调用阻塞的api，并不会转换到BLOCKED，依然是RUNNABLE状态，**JVM不关心操作系统调度相关的状态**，我们平时所谓的 Java 在调用阻塞式 API 时，线程会阻塞，指的是操作系统线程的状态，并不是 Java 线程的状态

因为在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 RUNNABLE 状态

个人理解：操作系统层面看待阻塞未阻塞是从有没有使用cpu，不使用cpu线程就是阻塞状态；而java站在自己的角度认为只有我主动调用了那一系列wait等的接口，自己主动发起的阻塞操作才被承认是阻塞了，等待分配cpu时间片、等待IO返回结果的时候，线程不能运行的原因并不是Java程序的问题，或者说对于Java程序来说我是想运行的，并且我也是可以运行的，我并没有阻塞。

### RUNNABLE与WAITING的状态转换

1. 获取到synchronized的隐式锁，然后调用Object的wait()方法。
2. 调用无参数的 Thread.join() 方法。其中的 join() 是一种线程同步方法，例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。 join内部调用的就是wait()方法。
3. 调用 LockSupport.park() 方法。其中的 LockSupport 对象，也许你有点陌生，其实 Java 并发包中的锁，都是基于它实现的。调用 LockSupport.park() 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。

### RUNNABLE与TIMED_WAITING的状态转换

1. 调用 **带超时参数**的Thread.sleep(long mills)方法
2. 获取synchronized隐式锁，调用带 **超时参数**的Object.wait(long timeout)方法
3. 调用 **带超时参数**的Thread.join(long mills)方法
4. 调用 **带超时参数**的LockSupport.parkNanos(Object blocker,long deadline)方法
5. 调用 **带超时参数**的LockSupport.partUntil(long deadline)方法

### 从NEW到RUNNABLE状态

只要调用 Thread对象的start方法就可以了。

### 从RUNNABLE到TERMINATED状态

当线程的run方法执行完了之后，或者自行run方法的时候异常抛出了，都会导致线程终止，或者可以调用interrupt方法来强制终止线程。Thread类中的stop方法已经被标记为了废弃

### stop和interrupt的主要区别

stop方法真的会杀死线程，不给任何喘息的机会，如果一个线程还没有来得及调用ReentrantLock的unLock方法释放锁，那其他线程就再也没有机会获取到锁，这太危险了，所以就不建议使用了，但是如果是synchronized隐式的锁时可以释放的。或者有finally的时候，在finally中释放ReentrantLock中的锁也是可以的。类似的还有suspend()和resume()方法。

interrupt() 就温顺的多interrupt仅仅是通知线程，线程有机会执行一些后续操作，同时也可以无视这个通知，被interrupt的线程可以主动检测中断或者通过异常的方式。

当线程A处于WAITING或者TIMED_WAITING状态的时候，如果其他线程调用线程的Interrupt方法，会使线程A返回RUNNABLE状态，同时线程A的代码会触发InterruptException异常，上面我们提到转换到WAITING或TIMED_WAITING状态的触发条件，都是类似于wait(),sleep(),join()这样的方法，他们都会抛出InterruptException异常，**这个异常的触发条件是：其他线程调用了该线程的interrupt()方法**

当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发 java.nio.channels.ClosedByInterruptException 这个异常；而阻塞在 java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 的 java.nio.channels.Selector 会立即返回。

当线程本来就处于RUNNABLE状态的时候，可以通过调用isInterrupt()方法，检测自己是不是被中断了。

理解 Java 线程的各种状态以及生命周期对于诊断多线程 Bug 非常有帮助，**多线程程序很难调试**，出了 Bug 基本上都是靠日志，靠线程 dump 来跟踪问题，分析线程 dump 的一个基本功就是分析线程状态，大部分的死锁、饥饿、活锁问题都需要跟踪分析线程的状态。同时，本文介绍的线程生命周期具备很强的通用性，对于学习其他语言的多线程编程也有很大的帮助。

可以借助jstack命令或者Java VisualVM可视化工具来分析线程状态，比如分析线程的死锁。

如果线程WAITING期间 被中断，会抛出中断异常，try catch捕获异常后，应该重置一下中断标志，因为抛出异常后，中断标志会自动清除掉。

```java
  try {
    Thread.sleep(100);
  }catch (InterruptedException e)｛
    Thread.currentThread().interrupt(); //这里就是重置中断标志
    e.printStackTrace();
  }
```

## 创建多少线程才是合适的

我们所谓的提高性能，从度量性能的角度，主要就是**降低延迟，提高吞吐量**，这也是我们使用多线的主要目的

延迟和吞吐量两个指标有一定的内在联系：同等情况下，延迟越短，吞吐量越大，但是因为他们隶属于不同的维度（一个空间维度，一个时间维度）并不能相互转换。

想要“降低延迟，提高吞吐量”，有两个方法：

1. 优化算法
2. 将硬件的性能发挥到极致（和并发编程息息相关)

在并发变成领域，提升性能本质上就是提升硬件的利用率,再具体点说，就是提高I/O的利用率和CPU的利用率

操作系统解决硬件利用率问题的对象往往是单一的硬件设备，而我们的并发程序，往往需要 CPU 和 I/O 设备相互配合工作，也就是说，**我们需要解决 CPU 和 I/O 设备综合利用率的问题**。关于这个综合利用率的问题，操作系统虽然没有办法完美解决，但是却给我们提供了方案，那就是：多线程

**假设CPU和IO之间的耗时是1:1的情况下，**![image-20210214101224600](D:\my_study\my_study\picture\image-20210214101224600.png)

此时如果只有一个线程，那么cpu和io的利用率个只有50%，因为进行CPU运算就不能进行IO运算，反之亦然

如果此时有两个线程：![image-20210214101334055](D:\my_study\my_study\picture\image-20210214101334055.png)

那么当线程A进行CPU运算的时候，线程B可以进行IO运算，反之亦然，CPU和IO的利用率就达到了100%，此时吞吐量相对于1个线程的时候，直接翻了一倍

因此：**如果CPU和IO的利用率很低，可以尝试通过增加线程数来提高吞吐量**

**假设是纯CPU计算任务**

在单核时代，对于纯粹的CPU计算，如果用多线程，反而会使性能变差， 因为没有IO计算，不需要平衡IO和CPU设备的利用率，因为是单核，如果用多线程，反而增加了变成切换的开销。

但是在多核时代，这种纯计算的程序也能利用多线程来提高性能。因为他可以降低计算的响应时间。

假设：计算 1+2+… … +100 亿的值，如果在 4 核的 CPU 上利用 4 个线程执行，线程 A 计算[1，25 亿)，线程 B 计算[25 亿，50 亿)，线程 C 计算[50，75 亿)，线程 D 计算[75 亿，100 亿]，之后汇总，那么理论上应该比一个线程计算[1，100 亿]快将近 4 倍，响应时间能够降到 25%。一个线程，对于 4 核的 CPU，CPU 的利用率只有 25%，而 4 个线程，则能够将 CPU 的利用率提高到 100%。

![image-20210214102642120](D:\my_study\my_study\picture\image-20210214102642120.png)

### 创建多少线程合适

IO密集型计算：我们的程序一般都睡CPU计算和IO操作交叉进行的，由于IO设备相对于CPU来说，速度都很慢，所以大部分情况下IO操作执行的时间相对于CPU来说都很长，这种场景我们一般称为IO密集型计算

CPU密集型计算：CPU密集型计算大部分场景下都是纯CPU计算，

IO密集型额CPU密集型，两种场景下，计算最佳线程数的方法是不同的。

1. 对于CPU密集型计算来说，多线程的本质就是提高cpu的利用率，因此线程的数量和CPU的核心数保持一致即可，再多了也只是增加线程的切换成本，不过，工程上我们一般会设置为 **CPU的核心数+1**，这样的话，当线程偶尔音内存缺页等其他原因导致阻塞的时候，这个额外的线程可以补上，保证cpu的利用率

2. 对于IO密集型计算：最佳的线程数是和程序中的CPU计算和IO操作的耗时相关的，可以通过如下公式：
   **最佳线程数=1+（I/O耗时/CPU耗时）**
   对于 I/O 密集型的计算场景，比如前面我们的例子中，如果 CPU 计算和 I/O 操作的耗时是 1:1，那么 2 个线程是最合适的。如果 CPU 计算和 I/O 操作的耗时是 1:2，那多少个线程合适呢？是 3 个线程，如下图所示：CPU 在 A、B、C 三个线程之间切换，对于线程 A，当 CPU 从 B、C 切换回来时，线程 A 正好执行完 I/O 操作。这样 CPU 和 I/O 设备的利用率都达到了 100%。

   ![image-20210214104305314](D:\my_study\my_study\picture\image-20210214104305314.png)我们令 R=I/O 耗时 / CPU 耗时，综合上图，可以这样理解：当线程 A 执行 IO 操作时，另外 R 个线程正好执行完各自的 CPU 计算。这样 CPU 的利用率就达到了 100%。
   多核CPU的计算公式如下：最佳线程数 =CPU 核数 * [ 1 +（I/O 耗时 / CPU 耗时）]

对于IO密集型计算，IO和CPU的时间耗时比是一个未知的参数，还是一个动态变化的数，所以工程上，我们要估算这个参数，然后做各种不同场景下的压测来验证我们的估计，不过工程上，原则还是 **将硬件的性能发挥到极致**，所以压测的时候我们需要重点关注CPU，IO设备的利用率和性能指标（响应时间，吞吐量）之间的关系

一类业务一个线程池比较好，比如smsThreadPool，mailThreadPool, calcThreadPool这样，因为线程池里线程数是有限的，当线程忙不过来的时候，任务就放到阻塞队列里了，用统一一个线程池，各种业务的任务在一起排队，如果前面业务处理的时间太常，就会影响阻塞队列里后面业务处理。

认为对于 I/O 密集型应用，最佳线程数应该为：2 * CPU 的核数 + 1，你觉得这个经验值合理吗？答案：大部分应用环境是合理的，老师也说了是积累了一些调优经验后给出的方案，没有特殊需求，初始值我会选大家都在用伪标准

apm工具可以测量 CPU和IO的耗时比。 apm工具可以精确到方法耗时，io相关的方法一般是知道的

对于网关这种服务，io时长和cpu时长的比例可能是99:1 ,那一个8核的网关服务的线程数是配置成8*（99+1）=800？

作者回复: 不是这样的，要看io模型是啥样的，nio和bio是不同的。实际场景和实验室场景差异太大，公式只能用来指导调优

## 利用面向对象的思想写好并发程序

> 在java语言里，面向对象思想能让并发编程变得更简单。

可以从 **封装共享变量 识别共享变量间的约束条件 制定并发访问策略** 三方面下手

### 封装共享变量

多线程同时访问同一个共享变量使我们要觉得一个并发程序问题。

利用面向对象的思想写并发程序的思路：**将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略** 如下代码所示：

```java
public class Counter {
  private long value; //这里就是将共享变量封装在了内部，
  synchronized long get(){ //这里对公开方法指定了并发访问策略，和addOne()都用同一个锁
    return value;
  }
  synchronized long addOne(){//这里对公开方法指定了并发访问策略，和get都用同一个锁
    return ++value;
  }
}
```

当然，实际工作中，很多的场景都不会像计数器这么简单，经常要面临的情况往往是有很多的共享变量，例如，信用卡账户有卡号、姓名、身份证、信用额度、已出账单、未出账单等很多共享变量。这么多的共享变量，如果每一个都考虑它的并发安全问题，那我们就累死了。但其实仔细观察，你会发现，很多共享变量的值是不会变的。对于信用卡好，姓名，身份证号等，**这些不会发生变化的共享变量，最好用final关键字来修饰**，这样技能避免并发问题，也能表明你的设计意图，表明你已经考虑过这些共享变量的并发问题了。

### 识别共享变量间的约束

识别共享变量间的约束条件很重要，因为这些 **约束条件，决定了并发访问策略**

例如对于如下设置库存的代码，假设库存是需要设置 *库存的上限和下限*  这就是共享变量间的约束条件

```java
public class SafeWM {
  // 库存上限
  private final AtomicLong upper =
        new AtomicLong(0);
  // 库存下限
  private final AtomicLong lower =
        new AtomicLong(0);
  // 设置库存上限
  void setUpper(long v){
    // 检查参数合法性
    if (v < lower.get()) {
      throw new IllegalArgumentException();
    } //这里因为我们要判断 “约束条件” 因此这里会发生竞态条件问题
    upper.set(v);
  }
  // 设置库存下限
  void setLower(long v){
    // 检查参数合法性
    if (v > upper.get()) {
      throw new IllegalArgumentException();
    } //这里因为我们要判断 “约束条件” 因此这里会发生竞态条件问题
    lower.set(v);
  }
  // 省略其他业务代码
}
```

**其实当我们看到 if语句的时候，就要考虑是否会发生竞态条件了** ，要识别所有共享变量之间的约束条件，约束条件识别不足，很可能导致并发访问策略南辕北辙 反应在代码里，一般都会有if判断，要留意

### 制定并发访问策略

1. 避免共享：避免共享的技术主要是利用线程本地存储以及每个任务分配独立的线程
2. 不变模式：这个在 Java 领域应用的很少，但在其他领域却有着广泛的应用，例如 Actor 模式、CSP 模式以及函数式编程的基础都是不变模式。
3. 管程与其他通信方式：Java 领域万能的解决方案是管程，但是对于很多特定场景，使用 Java 并发包提供的读写锁、并发容器等同步工具会更好

SDK：一种实现某种功能的软件包，他提供了API接口，可以让其他程序通过调用这个SDK提供的API接口，使用这个SDK提供的功能

如下宏观的原则有助于你写出“健壮”的并发程序：

1. **优先使用成熟的工具类**：java SDK并发包里提供了丰富的工具类，基本满足你日常的需要，我们要熟练的使用它们，而不是自己“发明轮子”，毕竟想发明一个没有bug的并发工具类也不容易
2. **迫不得已的时候才是用低级的同步源语**：低级的同步源语主要是指：synchronized，Lock，Semaphore等，这些虽然感觉简单，但实际上并不简单，要小心使用
3. **避免过早优化**：安全第一，并发程序首先要保证安全，出现性能瓶颈了，在优化，在设计期和开发期，很多人经常会情不自禁的预估性能的瓶颈，并对此进行优化，但是残酷的现实是：性能瓶颈不是你想预估就预估的。

Doug Lea《Java 并发编程：设计原则与模式》一书

个人理解：公平锁是直接先进入AQS同步队列，抢占锁。非公平锁，是先抢占锁，若没有抢到则进入AQS同步队列，等待唤醒。

1、公平锁能保证：老的线程排队使用锁，新线程仍然排队使用锁。
2、非公平锁保证：老的线程排队使用锁；**但是无法保证新线程抢占已经在排队的线程的锁**。

https://mp.weixin.qq.com/s/yxn47A4UcsrORoDJyREEuQ    jdk1.7HashMap put  死循环