## 1.时间，空间复杂度分析

> 复杂度分析是代码的精髓，掌握它，才能更好的对实现的算法进行性能分析

### 1.为什么需要复杂度分析

如果我们依赖机器跑算法的结果来区分不同算法的复杂度，会有以下的问题：

1. 测试非常依赖测试环境，换一个环境结果就可能完全不同
2. 测试结果受数据规模的影响大，数据太小可能无法真实的反应算法的性能，设置数据的顺序也会对算法的结果产生实质性的影响

### 2.大O表示法

我们对算法进行粗略的估计，会抛弃掉机器相关的影响，不考虑一个乘法其实是一个加法操作的多少倍，每一行语句，就认为程序执行了一次，无论这行语句执行的是什么。

```c

 int cal(int n) {
   int sum = 0;  //执行消耗1
   int i = 1;//执行消耗1
   for (; i <= n; ++i) {//执行消耗n
     sum = sum + i;//执行消耗n
   }
   return sum;//执行消耗1
 }
```

例如，如上的代码，复杂度就是 1+1+1+n+1 = 4+2n

也就是 **代码的执行时间T(n)和每行代码被执行的次数f(n)成正比** 

大O公式如下:

​	
$$
T(n)=O(f(n))
$$
f(n)表示每行代码执行次数的总和 比如上述的  4+2n就是个f(n) 也就是 T(n) = O(4+2n)

大O不是表示一个具体的时间，而是表示 随着数据规模的变大，算法执行时间随数据规模的增长趋势 也叫 **渐进时间复杂度，简称为时间复杂度**

当数据规模越来越大的时候，低阶项，常数项，也就不再是影响算法执行时间的关键，也就可以忽略，例如
$$
T(n) = O(4+2n) ≈ O(n)   又或者    T(n) = O(2n^2+2n+3) ≈ O(2n^2)
$$

### 3.如何分析时间复杂度

可以用如下的方式对算法的时间复杂度进行分析

1. 只关注循环执行次数最多的一段代码，因为它会和其他的代码形成幂级差。根据大O定义 低阶和常数都被忽略

2. 加法法则：总复杂度=量最大的那段代码的复杂度，如下例子所示

   ```c
   
   int cal(int n) {
      int sum_1 = 0;
      int p = 1;
      for (; p < 100; ++p) {
        sum_1 = sum_1 + p;
      }
   
      int sum_2 = 0;
      int q = 1;
      for (; q < n; ++q) {
        sum_2 = sum_2 + q;
      }
    
      int sum_3 = 0;  
      int i = 1;
      int j = 1;
      for (; i <= n; ++i) {//这两个for循环是复杂度最高的一块
        j = 1; 
        for (; j <= n; ++j) {
          sum_3 = sum_3 +  i * j;
        }
      }
    
      return sum_1 + sum_2 + sum_3;
    }
   ```

   注意 循环100000000次，他也是一个常量，只要他用实实在在的数字表示，他就是一个常量，当n无限大的时候，虽然他确实对代码产生实实在在的影响，但是 **时间复杂度说的是 一个算法随着数据规模的变大，他的时间花费的一个变化趋势 是趋势**

   因此上述代码 就是O(n^2) 也就是说 **总的时间复杂度就等于量级最大的那段代码的时间复杂度。**

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码执行次数的乘积（典型的双重for循环）

上述都是技巧，但是熟练了，就不需要这些技巧了

### 4.几种常见的算法复杂度分析

![image-20210728180850350](../picture/image-20210728180850350.png)

非多项式量级代码复杂度（NP问题）：上图中有两个
$$
O(2^n)  和   O(n!)
$$
其他的都会多项式量级的

非多项式量级的算法，随着数据的增加，执行时间飞速的上涨，他是一个低效的算法

**O(1):**

他表示一个常量级的算法复杂度，而不是只执行一次，比如代码for(; i <100;i++) 他也是O(1)的

一般情况下，只要代码中不存在循环，递归，计算有成千上万行代码，它的执行次数不会会数据的增大而变化，他就是O(1)的

2.**O(logn)和O(nlogn)**

对数阶是非常常见，而且很难分析例如：

```c

 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

上述代码就是一个对数阶的算法复杂度，上述循环执行的是一个等比数据，执行过程是如下

![image-20210728182059477](../picture/image-20210728182059477.png)

所以我们只要知道X的值是多少，就知道他的执行次数了，因为一共会执行x次，x= log2n 很明显

如果吧 i = i *2 换成 i=i * 3 效果一样 x = log3n

不管是以 几 为低，我们吧 对数阶的算法复杂度都计为 logn,因为对数之间 底数不同的对数是可以相互转换的，例如：
$$
O(log3n) = O(C *  log2n)
$$
其中C等于一个产量，在大O中我们是忽略常量系数的，所以 
$$
O(log2n)= O(log3n)
$$
其他常数也是如此，所以我们就统一用 logn代替了  

同理如O(nlogn) 他就是 循环了n遍，每一遍的复杂度都是logn

**3 O(m+n)、O(m*n)**

对于 O(m+n)来说 我们无法评估 m和n谁的量级大，不能简单的省略一个，所以就用了这种方式来表示 

O(m*n)同理

### 5 空间复杂度分析

> 空间复杂度就是表示，算法的存储空间和数据规模之间的增长关系

这里指的是代码需要的额外的存储空间，代码本身的不算，例如我们吧一个数组中的内容复制到另一个数组中，两个数据共存，空间复杂度就是O(n)

![image-20210728183105638](../picture/image-20210728183105638.png)

## 2.复杂度分析进阶

### 1.最好最坏情况复杂度

- 最好情况复杂度：就是在最理想的情况下，算法的时间复杂度
- 最坏情况复杂度：就是在最不理想的情况下，算法的时间复杂度

最好和最坏时间复杂度，都对应着极端情况下的结果，出现的概率不大，最坏时间复杂度效果可能还要更好一点。

### 2.平均时间复杂度：

- 平均时间复杂度：用来表示平均情况下，算法的执行效率

假设查找一个变量X是否在数据中

1. X只有两种情况，在数组中和不在数据中
2. 假设在数组中的概率为1/2 不在数组中的概率也是1/2
3. 同时 x所处的数据下标0-n中的任意位置的概率为1/n
4. 所以 x出现在某个位置的概率为  1/(2n) 就是2和3的总和

因此我们的平均时间复杂度为：

![image-20210816172959131](../picture/image-20210816172959131.png)

![img](https://static001.geekbang.org/resource/image/36/7f/36c0aabdac69032f8a43368f5e90c67f.jpg?wh=718*214)

转换成 O的标识法 就是 O(n),这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。

大多数情况下我们只需要个O(n)就可以了，不需要区分最好，最坏，平均的时间复杂度，除非这个代码在不同的情况下存在量级的差距（例如快速排序）我们才会使用

### 3.均摊时间复杂度

- 均摊时间复杂度主要使用 摊还分析方法进行计算

他的使用场景非常有限，比如说我们有个长度为16的数组，我们往这个数组插入数据，每次都插入末尾，插入的时间复杂度为O(1) ，但是当插入第17个元素的时候，需要扩容，此次插入时间就需要O(n)。这种情况下的复杂度是比较难以计算的，但是我们可以用摊还分析方法。

1. 假设数组的长度为N
2. 当我们插入前N个元素的时候，时间复杂度为O(1)
3. 当我们插入第N+1个元素的时候，时间复杂度为O(N)
4. 我们计算的时候，可以第三步的时间复杂度平摊到第二步中，此时 第二步的时间复杂度就相当于是"O(2)"
5. 我们知道常数无论都多大 时间复杂度都是O(1)
6. 因此总体上来讲，插入的时间复杂度就是O(1)
7. 着就是摊还分析

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上，一般能用均摊复杂度的场合他的时间复杂度基本上等于最好情况下的时间复杂度。

## 3.数组



## 2.二三树和红黑树

二叉查找树在极端情况下会退化为一条链表，

平衡查找树就是为了解决这个问题，让查询效率一直保持在O(nlogn)的时间复杂度，

avl平衡查找树的 插入，修改，删除的消耗太大了，因此虽然能很好的保持平衡树的特性，但是不够稳定

因此产生了红黑树，红黑树又来自于2-3树

### 2-3树

2-3树吧节点分为2节点和3节点，通过向上分裂的方式，保证树的平衡。

### 2节点

2节点就是有两个子节点的节点，它和二叉树中的节点一样，左节点小，右节点大。![image-20210811180411946](../picture/image-20210811180411946.png)

### 3节点

3节点就是就三个分支的节点，节点中存有两个元素，左侧的元素小于右侧的元素，同时存在左，中，右三个子节点，左子节点的元素小于当前节点中左侧的元素，中间节点的元素大于当前节点中左侧节点的元素，小于右侧节点的元素，右节点的元素大于当前节点右侧的元素

![image-20210811180730465](../picture/image-20210811180730465.png)

A>B>C>D>E>F

### 一个完整的2-3树如下：

![image-20210811180828240](../picture/image-20210811180828240.png)

### 2-3树的插入

对于插入要考虑如下几个条件

1.要插入新数据的节点是2节点

因为我们要控制树的高度，因此不能像插入二叉树一样，把节点和当前元素对比后，插入左侧或右侧。

我们插入的时候不想改变树的高度，于是把节点插入到父节点中，使父节点变成一个三节点，按照大小比较的规则插入，此时节点就变成了一个三节点，但这依然满足规则。

![image-20210811181708235](../picture/image-20210811181708235.png)

2.要插入新数据的节点是3节点

如果待插入的节点是一个三节点，如果这时候我们把数据直接插入这个节点，这个节点就会变成一个4节点，这就不符合我们2-3树的规范了。因此我们这个节点此时就要向上分裂，分裂会有三种情况

